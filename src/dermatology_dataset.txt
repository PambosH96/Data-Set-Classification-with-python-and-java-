# -*- coding: utf-8 -*-
"""Dermatology dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z4TkqCjLQGJbNSZIhM7jaJqWXJEXBKlX
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

data=pd.read_excel('new test.xlsx')

"""## EDA"""

data.head()

"""Λαμβανουμε πληροφοριες για το συνολο δεδομενων και κοιταζουμε αν υπαρχουν κενες τιμες"""

data.info()

"""Καθως ολες οι στηλες ειναι κατηγορηματικες,ελεγχουμε για μοναδικες τιμες σε καθε στηλη"""

for i in data.columns:
    print(data[i].unique(),"\t",data[i].nunique())

"""Ελεγχουμε τις τιμες εχουν συμπεριληφθει σε καθε κατηγορια"""

for i in data.columns:
    print(data[i].value_counts())
    print()

"""Απο τα παραπανω στοιχεια βλεπουμε πως εχουν κατηγοροιπηθει οι ασθενεις σε καθε χαρακτηριστικο και στο τελος και στις κλασεις

Παρακατω βλεπουμε ποσοι ασθενεις υπαρχουν σε καθε κλαση
"""

sns.countplot(data['Class'])

"""Φαινεται στις κλασεις δεν ειναι ολες ισοποσες υπαρχει αισθητη διαφορα της πρωτης και της εκτης απο τις υπολοιπες.

Και παρακατω βλεπουμε πως εχουν διανεμηθει οι κλασεις σε καθε χαρακτηριστικο
"""

for i in data.columns[:-1]:
    plt.figure(figsize=(12,6))
    plt.title("For feature '%s'"%i)
    sns.countplot(data[i],hue=data['Class'])



from sklearn.preprocessing import LabelEncoder

le=LabelEncoder()

for i in data.columns:
    data[i]=le.fit_transform(data[i])

data.head()

"""Ο χαρτης θερμοτητας των στηλων του αρχειο μας δειχνει τον συντελεστη συσχετισης Pearson's μεταξυ των στηλων"""

fig=plt.figure(figsize=(10,6))
sns.heatmap(data.corr(),annot=True)

"""X ειναι το πλαισιο δεδομενων που περιεχει δεδομενα εισοδου/χαρακτηριστηκα

y ειναι η σειρα που περιεχει αποτελεσματα που θα προβλεφτουν
"""

X=data[data.columns[:-1]]
y=data['Class']

X.head(2)

"""Χωριζουμε τα δεδομενα σε train and test"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""## Model Selection"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split,cross_val_score
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.neighbors import KNeighborsClassifier

#from sklearn.grid_search import GridSearchCV

from sklearn.model_selection import learning_curve,GridSearchCV

"""### Logistic Regression"""

logreg=LogisticRegression(solver='newton-cg',multi_class='multinomial')

logreg.fit(X_train,y_train)

pred=logreg.predict(X_test)

logreg.score(X_test,y_test)

"""Γενικα η  logistic regression μας δινει μια καλη ακριβεια. Παμε να ελεξουμε τις καμπυλες"""

lc=learning_curve(logreg,X_train,y_train,cv=10,n_jobs=-1)
size=lc[0]
train_score=[lc[1][i].mean() for i in range (0,5)]
test_score=[lc[2][i].mean() for i in range (0,5)]
fig=plt.figure(figsize=(12,8))
plt.plot(size,train_score)
plt.plot(size,test_score)

"""Απο το παραπανω γραφημα με τα δειγματα που εχει παρει βλεπουμε οτι η ακριβεια παραμενει καπου η ιδια .

Στην συνεχεια προσπαθησα να τροποποιησω την παραμετρο τακτοποιησης
"""

from sklearn.model_selection import learning_curve,cross_val_score,validation_curve
param_range=[0.0001,0.001,0.1,1]
curve=validation_curve(logreg,X_train,y_train,cv=5,param_name='C',
    param_range=param_range,n_jobs=-1,)

curve

n=len(param_range)
train_score=[curve[0][i].mean() for i in range (0,n)]
test_score=[curve[1][i].mean() for i in range (0,n)]
fig=plt.figure(figsize=(8,6))
plt.plot(param_range,train_score)
plt.plot(param_range,test_score)
plt.xticks=param_range

"""Ειναι φανερο οτι το C=0.1 μας δινει ενα  παρα πολυ καλο αποτελεσμα .

Τωρα καθως ειναι μια ταξινομηση πολλαπλων κλασεων μια και το αρχειο μας ειναι μικροτερο μπορω να χρησιμοποιησω  το GridSearch για να παρω τις καλυτερες παραμετρους
"""

param_grid={'C':[0.01,0.1,1,10],
           'solver':['newton-cg', 'lbfgs', 'sag'],
           'multi_class':['multinomial']}
grid=GridSearchCV(estimator=LogisticRegression(n_jobs=-1),param_grid=param_grid,cv=5,n_jobs=-1)

grid.fit(X_train,y_train)

print(grid.best_params_)
print(grid.best_score_)

"""Με τις παραπανω παραμετρους περνουμε ακριβεια γυρω στο 98,5%

### KNN Classifier

Τωρα θα δοκιμασω και τον KNN
"""

knn=KNeighborsClassifier(n_jobs=-1)

knn.fit(X_train,y_train)
pred=knn.predict(X_test)
knn.score(X_test,y_test)

"""Μας δινει ακριβεια γυρω στο 83,6 % που δεν ειναι και πολυ καλο ποσοστο"""

print(classification_report(y_test,pred))

"""Τωρα ελεγχω για διαφορες παραμετρους για 'n-γειτονες'.Μπορεις να το κανεις απευθειας με το grid_Search αλλα το εκανα χρησιμοποιωντας το κωδικα παρακατω για να απεικονισω τη επιδραση των 'n_γειτονων'"""

avg_score=[]
for k in range(2,30):
    knn=KNeighborsClassifier(n_jobs=-1,n_neighbors=k)
    score=cross_val_score(knn,X_train,y_train,cv=5,n_jobs=-1,scoring='accuracy')
    avg_score.append(score.mean())

plt.figure(figsize=(12,8))
plt.plot(range(2,30),avg_score)
plt.xlabel("n_neighbours")
plt.ylabel("accuracy")
#plt.xticks(range(2,30,2))

"""Οποτε και παλι με τον ΚΝΝ παιρνουμε μονο γυρω στο 83-86% ακριβεια

### Random Forests Classifier
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score

rfc=RandomForestClassifier(n_jobs=-1,random_state=51)

rfc.fit(X_train,y_train)
print(rfc.score(X_test,y_test))
print(f1_score(y_test,rfc.predict(X_test),average='macro'))

"""Με το RFC παιρνουμε γυρω στο 95,6% ακριβεια

Τωρα ελεγχω την επιδραση των 'n_εκτιμητων' του μοντελου
"""

param_range=[10,25,50,100]
curve=validation_curve(rfc,X_train,y_train,cv=5,param_name='n_estimators',
    param_range=param_range,n_jobs=-1)

train_score=[curve[0][i].mean() for i in range (0,len(param_range))]
test_score=[curve[1][i].mean() for i in range (0,len(param_range))]
fig=plt.figure(figsize=(6,8))
plt.plot(param_range,train_score)
plt.plot(param_range,test_score)
plt.xticks=param_range

"""Οποτε με την αυξηση των 'n_εκτιμητων' το ποσοστο ακριβειας αυξανεται. το μοντελο εκτιμα καλυτερα οταν οι 'n_εκτιμητες'=50 ειδαλως μετα αρχιζει το overfitting.Τωρα εχουμε γυρω στο 98%

Ελεγχω τωρα πως το μοντελο ταιριαζει σε διαφορες τιμες των 'max_features'.
"""

param_range=range(1,len(X.columns)+1)
curve=validation_curve(RandomForestClassifier(n_estimators=50,n_jobs=-1,random_state=51),X_train,y_train,cv=5,
    param_name='max_features',param_range=param_range,n_jobs=-1)

train_score=[curve[0][i].mean() for i in range (0,len(param_range))]
test_score=[curve[1][i].mean() for i in range (0,len(param_range))]
fig=plt.figure(figsize=(6,8))
plt.plot(param_range,train_score)
plt.plot(param_range,test_score)
plt.xticks=param_range

"""Απο το παραπανω γραφημα το μοντελο μας δινει γυρω στο 97%

Μπορουμε επισης να ελεξουμε για αλλες παραμετρους οπως 'max_depth'με τον πιο πανω κωδικα. Ακομα ενας ευκολος τροπος ειναι να χρησιμοποιησουμε το Gridsearch για να παρουμε ενα συνδιασμο απο τις καλυτερες παραμετρους
"""



param_grid={'criterion':['gini','entropy'],
           'max_depth':[2,5,10,20],
           'max_features':[2,4,6,'auto'],
           'max_leaf_nodes':[2,3,None],}

grid=GridSearchCV(estimator=RandomForestClassifier(n_estimators=50,n_jobs=-1,random_state=51),
                  param_grid=param_grid,cv=10,n_jobs=-1)

grid.fit(X_train,y_train)

print(grid.best_params_)
print(grid.best_score_)

"""Με τις παραπανω παραμετρους για το RFC εχουμε φτασει το 98.43% ποσοστο ακριβειας

## Conclusion
Random Forest Classifier και logistic regression ειναι τα καλυτερα μοντελα για αυτα τα δεδομενα με τις παραμετρους που εκχωρησαμε φτασαμε να παιρνουμε πανω απο 98% ακριβεια
"""